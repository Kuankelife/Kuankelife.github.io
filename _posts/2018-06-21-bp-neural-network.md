---
layout:     post
title:  "一场艰难的历程：BP神经网络预测股票涨跌"
subtitle: ''
date:       2018-06-21 00:55:00
author:     "YU"
header-img: "https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=3459424699,700044990&fm=26&gp=0.jpg"
catalog: true
tags:
    - 数据科学
    - 机器学习
    - Python
    - 量化投资
    - 神经网络

---

# <center>BP神经网络预测股票涨跌</center>

## l  引言

众所周知，股票价格受到经济、政治、人们心理等许多错综复杂因素的影响。而这些因素是没有确定的规则可以描述的。在这方面，人工神经元网络具有较大优势，所以经济、财政分析是人工神经网络的重要应用领域。

人工神经网络（Artificial Neural Networks——ANNs）提供了一种普遍而且实用的方法，来从样例中学习值为实数、离散或向量的函数。像反向传播（BackPropagation）这样的算法使用梯度下降来调节网络参数以最佳拟合由输入-输出对组成的训练集合。ANN 学习对于训练数据中的错误鲁棒性很好，且已经成功地应用到很多领域，例如视觉场景分析（interpreting visual scenes）、语音识别、以及机器人控制等。

## l  多层网络和反向传播原理

单个感知器仅能表示线性决策面，而反向传播算法所学习的多层网络能够表示种类繁多的非线性曲面。

## 一、      可微阈值单元

我们所需要的是这样的单元，它的输出是输入的非线性函数，并且输出是输入的可微函数一种答案是sigmoid单元（sigmoid unit），这是一种非常类似于感知器的单元，但它基于一个平滑的可微阈值函数。

​   ![1538317633592](/img/yu-img/post-img/20180930/1538317633592.png)                           




图1画出了sigmoid单元。与感知器相似，sigmoid单元先计算它的输入的线性组合，然后应用一个阈值到此结果。然而，对于sigmoid单元，阈值输出是输入的连续函数。更精确地讲，sigmoid 单元这样计算它的输出：

   

其中

![1538317725078](/img/yu-img/post-img/20180930/1538317725078.png)

   经常被称为 sigmoid 函数或者也可以称为 logistic 函数（logistic function）。注意它的输出范围为 0 到 1，随输入单调递增。因为这个函数把非常大的输入值域映射到一个小范围的输出，它经常被称为sigmoid单元的挤压函数（squashing function）。

## 二、      反向传播算法

对于由一系列确定的单元互连形成的多层网络，反向传播算法可用来学习这个网络的权值。它采用梯度下降方法试图最小化网络输出值和目标值之间的误差平方。

因为我们要考虑多个输出单元的网络，而不是象以前只考虑单个单元，所以我们先重新定义误差 E，以便对所有网络输出的误差求和。

   

其中 outputs 是网络输出单元的集合，   和   是与训练样例d和第k个输出单元相关的输出值。

​             ![1538317749876](/img/yu-img/post-img/20180930/1538317749876.png)

​          **包含两层sigmoid单元的前馈网络的反向传播算法（随机梯度下降版本****）**     **Backpropagation(training_examples,****η****,**           **,**           **,**           **)**              trainning_exaples 中每一个训练样例是形式为           的序偶，其中           是网络输入值向量，           是目标输出值。              η是学习速率（例如0.05）。           是网络输入的数量，           是隐藏层单元数，           是输出单元数。              从单元           到单元j的输入表示为           ，单元i到单元j的权值表示为           。     l            创建具有           个输入，           个隐藏单元，           个输出单元的网络     l  初始化所有的网络权值为小的随机值（例如-0.05和0.05之间的数）     l  在遇到终止条件前，做     n          对于训练样例training_examples中的每个           ,做     **把输入沿网络前向传播**     1.    把实例           输入网络，并计算网络中每个单元 u 的输出           。     **使误差沿网络反向传播**     2.            对于网络的每个输出单元k，计算它的误差项                                3.            对于网络的每个隐藏单元h，计算它的误差项                                4.            更新每个网络权值                                     

​          **包含两层sigmoid单元的前馈网络的反向传播算法（随机梯度下降版本****）**     **Backpropagation(training_examples,****η****,**                                                                                                                                  **,**           **,**           **)**              trainning_exaples 中每一个训练样例是形式为           的序偶，其中           是网络输入值向量，           是目标输出值。              η是学习速率（例如0.05）。           是网络输入的数量，           是隐藏层单元数，           是输出单元数。              从单元           到单元j的输入表示为           ，单元i到单元j的权值表示为           。     l            创建具有           个输入，           个隐藏单元，           个输出单元的网络     l  初始化所有的网络权值为小的随机值（例如-0.05和0.05之间的数）     l  在遇到终止条件前，做     n          对于训练样例training_examples中的每个           ,做     **把输入沿网络前向传播**     1.    把实例           输入网络，并计算网络中每个单元 u 的输出           。     **使误差沿网络反向传播**     2.            对于网络的每个输出单元k，计算它的误差项                                3.            对于网络的每个隐藏单元h，计算它的误差项                                4.            更新每个网络权值                                     

## l  代码实现

Pybrain是一个 Python的神经网络库。其实Scikit-Learn号称Python上最好用的机器学习库，但是它偏偏就没有神经网络这块，而pybrain在神经网络的搭建上相对方便。

**一、**   **构造神经网络**

1.我们构建的是BP神经网络，即前馈神经网络，自己设定神经网络

搭建了三层和四层神经网络层，分别进行测试。

2.设立三层，一层输入层（3个神经元，别名为inLayer），一层隐藏层，一层输出层

**二、**   **构造数据集**

以上证50的50只股票数据作为样本集 

 

**三、**   **训练神经网络**

1.选取了股票最低价、最高价、开盘价、收盘价、成交量、PE、PB、换手率八个因子作为输入值，下一日股票的价格作为输出值。

回测逻辑为输出的预测股票收盘价价格与昨天收盘价价格之比，排序，选取10%的股票加入买的股票池，不在股票池的进行卖出，均匀持仓

回测结果：

**三层神经网络**（八个输入层，10个隐藏层，1个输出层）

![1538317825876](/img/yu-img/post-img/20180930/1538317825876.png)


​      ![1538317863106](/img/yu-img/post-img/20180930/1538317863106.png)

**四层神经网络**（4个输入点，10个隐藏点，10个隐藏点，1个输出点）

​      ![1538317878325](/img/yu-img/post-img/20180930/1538317878325.png)

**四、**   **改进**

可见三层跟四层相差不大，四层训练时间较长，故搭建三层神经网络

选取了股票最低价、最高价、开盘价、收盘价四个因子作为输入值，下一日股票的涨跌作为输出值。

**改进一**

（1）.牛市和震荡时期的样本作为训练集

​         2010年到2014年时期的样本作为训练集

start_train_date = '20100101'

end_train_date = '20140101'

训练标签：涨设为1，否则设为0

样本外测试（2015年1月1日到2017年12月11日）

准确率：

上证50总体准确率：48%

沪深300总体准确率：47%

 

（2）.震荡时期的样本作为训练集

start_train_date = '20140401'

end_train_date = '20141105'

训练标签：涨幅大于0.01设为1，否则设为0

样本外测试（2015年1月1日到2017年12月11日）

准确率：    

上证50（50只股票）

总体准确率：42%

上涨预测总体准确率：42%

下跌预测总体准确率：50%

沪深300（300只股票）

总体准确率：43%

上涨预测总体准确率：40%

下跌预测总体准确率：49%

全A股（所有A股）

总体准确率：42%

上涨预测总体准确率：45%

下跌预测总体准确率48%

 

（3）.牛市时期的样本作为训练集

start_train_date = '20141001'

end_train_date = '20150101'

训练标签：涨幅大于0.01设为1，否则设为0

样本外测试（2015年1月1日到2017年12月11日）

准确率：

上证50（50只股票）

总体准确率：45%

上涨预测总体准确率：50%

下跌预测总体准确率：49%

沪深300（300只股票）

总体准确率：45%

上涨预测总体准确率：45%

下跌预测总体准确率：49%

全A股（所有A股）

总体准确率：44%

上涨预测总体准确率：44%

下跌预测总体准确率：49%

**改进二**

接着由原来一个输出层设为两个输出层，一个标签为当日涨跌，第二个标签为第二天涨跌 

测试准确率，发现总体仍没达到50%准确率 

**改进三**

接下来建立两个神经网络，输出层都是1个，标签分别是当日涨跌和第二天涨跌，分别训练，最低价、最高价、开盘价、收盘价四个因子作为输入值，当输出层预测第二天比当天预测 大，说明上涨 。

（1）上证50（50只股票）

总体准确率：53%

上涨预测总体准确率：47%

下跌预测总体准确率：60%

（2）沪深300（300只股票）

总体准确率：48%

上涨预测总体准确率：46%

下跌预测总体准确率：56%

（3）全A股

总体准确率：48%

上涨预测总体准确率：46%

下跌预测总体准确率：56%



**五、**  **分析与验证**

1.选取了股票最低价、最高价、开盘价、收盘价、成交量、PE、PB、换手率八个因子作为输入值，下一日股票的价格作为输出值，发现预测的值都是同一个值，这明显不合理，但神经网络内部权重的机制尚未有合理的解释，但回测逻辑为输出的预测股票收盘价价格与昨天收盘价价格之比，排序，选取10%的股票加入买的股票池，不在股票池的进行卖出，均匀持仓，发现在上证50或者沪深300上可以跑赢大盘。



2.选取了股票最低价、最高价、开盘价、收盘价四个因子作为输入值，下一日股票的涨跌作为输出值。发现在设置标签时，涨的很少的时候也贴为1，这准确率上不来，接着把涨幅大于或者等于0.01的情况设为1，在两种样本测试，在典型震荡市或牛市做训练集时，预测后面的涨跌发现准确率并没有提升,说明四个因子不足以提高准确率。



3构建两个网络层，选取了股票最低价、最高价、开盘价、收盘价四个因子作为输入值，分别以当日股票的涨跌和下一日股票的涨跌作为输出值，发现准确率有所提升，标签的选取对提高神经网络的学习也有关系。

 

**七、**  **下一步改进**

可以用添加更多有效的因子，用循环神经网络和长短期神经网络

**八、**  **代码**

需要代码请与我联系。